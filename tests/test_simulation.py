import sys
import time
from pathlib import Path

import numpy as np
import pytest

# Import necessary modules from your project
from pyfracval import main_runner, particle_generation, utils

# Ensure the main project directory is in the Python path
# Adjust the path depth ('..') as necessary based on your structure
# project_dir = Path(__file__).resolve().parent.parent
# sys.path.insert(0, str(project_dir))


# --- Test Configurations ---

# Simple config for quick end-to-end run
CONFIG_SIMPLE = {
    "N": 32,
    "Df": 1.8,
    "kf": 1.3,
    "rp_g": 10.0,
    "rp_gstd": 1.0,  # Monodisperse for simplicity
    "tol_ov": 1e-5,  # Slightly looser for robustness maybe
    "n_subcl_percentage": 0.2,  # Larger % for fewer, bigger subclusters with small N
    "ext_case": 0,
    "seed": 123,
}

# Config for fractal dimension check (matching the paper's example)
CONFIG_FRACTAL_CHECK = {
    "N": 128,  # Larger N for better statistics
    "Df": 1.79,
    "kf": 1.40,
    "rp_g": 15.0,
    "rp_gstd": 1.0,  # Monodisperse like Fig 10/13a
    "tol_ov": 1e-6,
    "n_subcl_percentage": 0.1,
    "ext_case": 0,
    "seed": 456,
}

# Config for polydisperse fractal check
CONFIG_FRACTAL_CHECK_POLY = {
    "N": 128,
    "Df": 1.68,  # Df used for sigma=2.0 in Fig 13b
    "kf": 0.98,  # kf used for sigma=2.0 in Fig 13b
    "rp_g": 15.0,
    "rp_gstd": 2.0,  # Polydisperse
    "tol_ov": 1e-6,
    "n_subcl_percentage": 0.1,
    "ext_case": 0,
    "seed": 789,
}


# --- Fixtures ---


@pytest.fixture(scope="module")  # Run once per test module
def output_dir(tmp_path_factory):
    """Create a temporary directory for test outputs."""
    path = tmp_path_factory.mktemp("fracval_test_outputs")
    print(f"Test output directory: {path}")
    yield str(path)  # Yield the path string
    # Cleanup is handled by tmp_path_factory automatically
    # print(f"Cleaning up test output directory: {path}") # Optional: confirm cleanup


@pytest.fixture(
    scope="module",
    params=[CONFIG_SIMPLE, CONFIG_FRACTAL_CHECK, CONFIG_FRACTAL_CHECK_POLY],
)
def simulation_run_data(request, output_dir):  # Request output_dir fixture
    """
    Runs the simulation once for a given config and provides results.
    Parametrized fixture to run tests for different configs.
    """
    cfg = request.param
    print(
        f"\nRunning simulation for test config (N={cfg['N']}, Df={cfg['Df']}, sigma={cfg['rp_gstd']})..."
    )

    run_id = f"test_N{cfg['N']}_Df{cfg['Df']}_Kf{cfg['kf']}_Sig{cfg['rp_gstd']}"
    test_seed = cfg.get("seed", int(time.time()))

    initial_radii = particle_generation.lognormal_pp_radii(
        cfg["rp_gstd"], cfg["rp_g"], cfg["N"], seed=test_seed
    )
    if np.any(initial_radii <= 0):
        pytest.fail("Generated non-positive initial radii.")

    # --- Run Simulation ---
    # Pass the temporary directory path generated by the output_dir fixture
    # to the run_simulation function using the 'output_base_dir' argument.
    success, final_coords, final_radii = main_runner.run_simulation(
        iteration=1,  # Run only iteration 1 for test
        sim_config=cfg,
        output_base_dir=output_dir,  # <<< PASS THE TEMP PATH HERE
        seed=test_seed,
    )
    # ... (rest of the fixture remains the same: check success, load results etc.) ...

    if not success:
        pytest.fail(f"Simulation run failed for config: {cfg}")

    # --- Load Results ---
    n_str = f"{cfg['N']:08d}"
    iter_str = f"{1:08d}"  # Iteration 1
    # Use the output_dir passed to run_simulation to find the file
    expected_filename = Path(output_dir) / f"N_{n_str}_Agg_{iter_str}.dat"

    if not expected_filename.is_file():
        pytest.fail(f"Output file not found: {expected_filename}")

    # ... (rest of loading and returning data) ...
    try:
        loaded_data = np.loadtxt(expected_filename)
        if (
            loaded_data.ndim == 1 and cfg["N"] == 1
        ):  # Handle case of single particle output
            loaded_data = loaded_data.reshape(1, -1)
        elif loaded_data.ndim != 2 or loaded_data.shape[1] != 4:
            pytest.fail(
                f"Output file has wrong shape: {loaded_data.shape}, expected ({cfg['N']}, 4)"
            )

        final_coords = loaded_data[:, :3]
        final_radii = loaded_data[:, 3]

        if final_coords.shape[0] != cfg["N"]:
            pytest.fail(
                f"Output file has wrong number of particles: {final_coords.shape[0]}, expected {cfg['N']}"
            )

    except Exception as e:
        pytest.fail(f"Failed to load or parse output file {expected_filename}: {e}")

    return {
        "config": cfg,
        "initial_radii": initial_radii,
        "final_coords": final_coords,
        "final_radii": final_radii,
        "output_filename": expected_filename,
    }


# --- Test Functions ---


def test_simulation_completes(simulation_run_data):
    """Tests if the simulation runs to completion and creates an output file."""
    print(f"Checking completion for N={simulation_run_data['config']['N']}...")
    assert simulation_run_data is not None, "Simulation run fixture failed"
    assert simulation_run_data["output_filename"].is_file(), (
        "Output file was not created"
    )
    print("Completion check passed.")


def test_output_file_format(simulation_run_data):
    """Tests if the output file has the correct number of particles and columns."""
    print(f"Checking output format for N={simulation_run_data['config']['N']}...")
    cfg = simulation_run_data["config"]
    n_expected = cfg["N"]
    final_coords = simulation_run_data["final_coords"]
    final_radii = simulation_run_data["final_radii"]

    assert final_coords.shape[0] == n_expected, (
        f"Expected {n_expected} particles, found {final_coords.shape[0]}"
    )
    assert final_coords.shape[1] == 3, (
        f"Expected 3 coordinate columns, found {final_coords.shape[1]}"
    )
    assert final_radii.shape[0] == n_expected, (
        f"Expected {n_expected} radii, found {final_radii.shape[0]}"
    )
    assert np.issubdtype(final_coords.dtype, np.number), "Coordinates are not numeric"
    assert np.issubdtype(final_radii.dtype, np.number), "Radii are not numeric"
    print("Output format check passed.")


def test_fractal_properties(simulation_run_data):
    """
    Tests if the generated aggregate approximately matches the target Df and kf
    by comparing the calculated Rg with the expected Rg.
    """
    cfg = simulation_run_data["config"]
    N = cfg["N"]
    target_Df = cfg["Df"]
    target_kf = cfg["kf"]
    initial_radii = simulation_run_data["initial_radii"]
    final_coords = simulation_run_data["final_coords"]
    final_radii = simulation_run_data["final_radii"]  # Radii in the final aggregate

    print(
        f"Checking fractal properties for N={N}, Df={target_Df}, kf={target_kf}, sigma={cfg['rp_gstd']}..."
    )

    if N < 5:  # Fractal scaling is less meaningful for very small N
        pytest.skip("Skipping fractal property check for N < 5")
        return

    # 1. Calculate geometric mean radius (rp,geo) of the *initial* particles
    valid_initial_radii = initial_radii[initial_radii > 1e-12]
    if len(valid_initial_radii) == 0:
        pytest.fail("No valid initial radii found to calculate rp,geo")
    log_radii = np.log(valid_initial_radii)
    rp_geo = np.exp(np.mean(log_radii))
    print(f"  Calculated rp,geo from initial radii: {rp_geo:.4f}")

    # 2. Calculate Radius of Gyration (Rg) of the *final* aggregate
    # Use the utility function (assuming it correctly handles mass weighting)
    # We need the masses corresponding to the *final* radii
    # Since density is constant, mass ~ radius^3. We can use radii directly
    # if the function handles it, or calculate final masses.
    # Let's assume calculate_cluster_properties handles it.
    try:
        # Need to ensure the calculate_cluster_properties function exists and is correct
        m_total, rg_calculated, cm, r_max = utils.calculate_cluster_properties(
            final_coords,
            final_radii,
            target_Df,
            target_kf,  # Pass target Df/kf? Or dummy values? Pass target.
        )
        print(f"  Calculated Rg of final aggregate: {rg_calculated:.4f}")
    except AttributeError:
        pytest.fail("utils.calculate_cluster_properties function not found or failed.")
    except Exception as e:
        pytest.fail(f"Error calculating final Rg: {e}")

    if rg_calculated <= 0:
        pytest.fail(f"Calculated Rg is non-positive ({rg_calculated:.4f})")

    # 3. Calculate the *expected* Rg based on the input N, Df, kf, and calculated rp_geo
    # From N = kf * (Rg / rp,geo)^Df  =>  Rg = rp,geo * (N / kf)^(1/Df)
    if target_kf <= 0 or target_Df <= 0:
        pytest.fail("Input kf or Df is non-positive.")
    try:
        rg_expected = rp_geo * (N / target_kf) ** (1.0 / target_Df)
        print(f"  Expected Rg based on input parameters: {rg_expected:.4f}")
    except (ValueError, ZeroDivisionError, OverflowError) as e:
        pytest.fail(f"Error calculating expected Rg: {e}")

    # 4. Compare calculated Rg vs expected Rg
    # Allow for some deviation, especially for smaller N or higher polydispersity
    # Relative tolerance: 15% might be reasonable for single aggregate check?
    # Adjust tolerance based on expected algorithm accuracy and N.
    tolerance = 0.20  # Allow 20% relative difference
    assert rg_calculated == pytest.approx(rg_expected, rel=tolerance)
    print(
        f"Fractal property check passed (Relative difference: {abs(rg_calculated - rg_expected) / rg_expected:.3f} <= {tolerance})."
    )
